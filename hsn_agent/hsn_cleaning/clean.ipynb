{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08dcd263",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b79f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_duty_value(x):\n",
    "    \"\"\"\n",
    "    - \"Rs. 42 / kg\" or \"₹42/kg\"    -> (42.0, \"INR/kg\")\n",
    "    - \"120/kg\"                     -> (120.0, \"INR/kg\")\n",
    "    - plain number \"10\"            -> (0.10, \"percentage\")\n",
    "    - numeric 10 or 10.0           -> (0.10, \"percentage\")\n",
    "    - NaN/empty                    -> (None, None)\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return None, None\n",
    "\n",
    "    # Numeric → percentage\n",
    "    if isinstance(x, (int, float)):\n",
    "        return float(x) / 100.0, \"percentage\"\n",
    "\n",
    "    s = str(x).strip()\n",
    "\n",
    "    # 1) Currency-per-unit pattern\n",
    "    m = re.match(r'(?:Rs\\.?|₹)?\\s*([\\d\\.]+)\\s*/\\s*(\\w+)', s, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        value = float(m.group(1))\n",
    "        unit  = m.group(2)\n",
    "        return value, f\"INR/{unit}\"\n",
    "\n",
    "    # 2) Pure number → percentage\n",
    "    if re.fullmatch(r'[\\d\\.]+', s):\n",
    "        return float(s) / 100.0, \"percentage\"\n",
    "\n",
    "    return None, None\n",
    "\n",
    "def format_duty(value, unit):\n",
    "    if value is None or pd.isna(value):\n",
    "        return \"\"\n",
    "    if unit == \"percentage\":\n",
    "        return f\"{value * 100:.2f}%\"\n",
    "    else:\n",
    "        # e.g. unit == \"INR/kg\"\n",
    "        return f\"{value:.2f} {unit}\"\n",
    "\n",
    "def normalize_and_prepare_display(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy().applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    duty_cols = [\n",
    "        'Basic Duty (SCH)',\n",
    "        'Basic Duty (NTFN)',\n",
    "        'Specific Duty (Rs)',\n",
    "        'IGST',\n",
    "        '10% SWS',\n",
    "        'Total duty with SWS of 10% on BCD',\n",
    "        'Total Duty Specific',\n",
    "        'Pref. Duty (A)',\n",
    "    ]\n",
    "\n",
    "    for col in duty_cols:\n",
    "        if col not in df:\n",
    "            continue\n",
    "        parsed = df[col].apply(parse_duty_value)\n",
    "        df[f'{col}_value'], df[f'{col}_unit'] = zip(*parsed)\n",
    "        df[f'{col}_display'] = [\n",
    "            format_duty(v, u) for v, u in zip(df[f'{col}_value'], df[f'{col}_unit'])\n",
    "        ]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example:\n",
    "# df_raw = pd.read_excel('chapter.xlsx')\n",
    "# df_out = normalize_and_prepare_display(df_raw)\n",
    "# df_out[['IGST_display','Specific Duty (Rs)_display']]\n",
    "#   might show: [\"10.00%\",   \"42.00 INR/kg\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d4b2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_policy_links(cell: str):\n",
    "    \"\"\"\n",
    "    From a string like \"Restricted*1,2\" or \"Free*\" or \"Conditional2\":\n",
    "      - returns (\"Restricted\", [\"*\",\"1\",\"2\"])\n",
    "      - returns (\"Free\", [\"*\"])\n",
    "      - returns (\"Conditional\", [\"2\"])\n",
    "    If no trailing markers, returns (original_text, []).\n",
    "    \"\"\"\n",
    "    if pd.isna(cell) or not isinstance(cell, str):\n",
    "        return None, []\n",
    "\n",
    "    s = cell.strip()\n",
    "    # split off trailing sequence of *, digits and commas\n",
    "    m = re.match(r'^(?P<text>.*?)(?P<refs>[\\*\\d,]+)$', s)\n",
    "    if not m:\n",
    "        return s, []\n",
    "\n",
    "    base, refs = m.group(\"text\").strip(), m.group(\"refs\")\n",
    "    # normalize refs into list of individual tokens\n",
    "    tokens = []\n",
    "    for part in refs.split(','):\n",
    "        part = part.strip()\n",
    "        if not part:\n",
    "            continue\n",
    "        # if it's multiple asterisks, keep each\n",
    "        if set(part) == {\"*\"}:\n",
    "            tokens += [\"*\"] * len(part)\n",
    "        else:\n",
    "            # each character that is a digit\n",
    "            tokens += list(part)\n",
    "    return base, tokens\n",
    "\n",
    "def attach_policy_links(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for col in (\"Import Policy\", \"Export Policy\"):\n",
    "        if col not in df:\n",
    "            continue\n",
    "\n",
    "        extracted = df[col].apply(extract_policy_links)\n",
    "        df[f\"{col}_text\"], df[f\"{col}_note_refs\"] = zip(*extracted)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b002aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: your existing compute_level (for Tariff rows only)\n",
    "def seed_base_level(row):\n",
    "    lvl = row.get(\"Level\")\n",
    "    desc = str(row.get(\"Item Description\",\"\")).strip().lower()\n",
    "    # Chapter headers always level = 0\n",
    "    if desc.startswith(\"chapter\"):\n",
    "        return 0\n",
    "    # hyphens → level = count of hyphens\n",
    "    if isinstance(lvl, str) and re.fullmatch(r\"-+\", lvl.strip()):\n",
    "        return len(lvl.strip())\n",
    "    # otherwise leave as None (so we don’t accidentally force zeros)\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf9d9199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_excel_read(input_file: str):\n",
    "  # Read the Excel file\n",
    "  df = pd.read_excel(input_file)\n",
    "  df.columns = (\n",
    "  df.columns\n",
    "    .str.strip()                      # remove leading/trailing spaces\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)  # collapse inner whitespace\n",
    "  )\n",
    "\n",
    "  # Normalize and prepare display\n",
    "  df = normalize_and_prepare_display(df)\n",
    "  # Attach policy links\n",
    "  df = attach_policy_links(df) \n",
    "  # apply it\n",
    "  df[\"level\"] = df.apply(seed_base_level, axis=1)\n",
    "\n",
    "  # 2) Now override only the Tariff rows\n",
    "  mask = df[\"Remark\"] == \"Tariff\"\n",
    "\n",
    "  # a) 4-digit HSN → level 1\n",
    "  mask_4d = mask & df[\"HS Code\"].astype(str).str.fullmatch(r\"\\d{4}\")\n",
    "  df.loc[mask_4d, \"level\"] = 1\n",
    "\n",
    "  # b) hyphens in Level → level = hyphens count + 1\n",
    "  def hyphens_plus_one(s):\n",
    "    return len(s.strip()) + 1\n",
    "  mask_hyph = mask & df[\"Level\"].astype(str).str.fullmatch(r\"-+\")\n",
    "  df.loc[mask_hyph, \"level\"] = df.loc[mask_hyph, \"Level\"].apply(hyphens_plus_one)\n",
    "\n",
    "  # c) any other Tariff row (no HSN-4 or hyphens) → fallback level 1\n",
    "  mask_other = mask & ~mask_4d & ~mask_hyph\n",
    "  df.loc[mask_other, \"level\"] = 1\n",
    "\n",
    "\n",
    "  df.to_excel(f\"{input_file}_with_links.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ad823be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/07/y36f8rx151z3xys0mnl4p0y40000gn/T/ipykernel_49654/3302561760.py:41: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.copy().applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "main_excel_read(\"Chapter 25.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55cc452f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved hierarchical JSON with 1 top-level nodes to hierarchy_ver3.json\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical JSON Generator (Jupyter Notebook)\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def build_hierarchy(\n",
    "    df,\n",
    "    level_col='level',\n",
    "    remark_col='Remark',\n",
    "    note_text_cols=None,\n",
    "    hs_code_col='HS Code'\n",
    "):\n",
    "    \"\"\"\n",
    "    Build nested hierarchy:\n",
    "    - Normalize HS Code by stripping all spaces.\n",
    "    - Node rows: any row where remark_col != 'Notes'. level_col gives depth (NaN → 0).\n",
    "    - Note rows (remark_col == 'Notes'): attach to most recent level-1 node if exists, otherwise level-0.\n",
    "    - Discontinuous levels attach under nearest existing ancestor < current level.\n",
    "    \"\"\"\n",
    "    # Clean headers and normalize HS Code\n",
    "    df = df.rename(columns=lambda c: c.strip())\n",
    "    df[hs_code_col] = df[hs_code_col].apply(\n",
    "        lambda x: str(x).replace(' ', '') if pd.notna(x) else x\n",
    "    )\n",
    "    \n",
    "    if note_text_cols is None:\n",
    "        note_text_cols = ['Item Description']\n",
    "\n",
    "    root = []\n",
    "    level_nodes = {}   # depth -> last node at that depth\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        remark = str(row.get(remark_col)).strip()\n",
    "\n",
    "        if remark != 'Notes':\n",
    "            # Node row\n",
    "            raw_lvl = row.get(level_col)\n",
    "            try:\n",
    "                depth = int(raw_lvl) if pd.notna(raw_lvl) else 0\n",
    "            except:\n",
    "                depth = 0\n",
    "\n",
    "            # Copy all columns and add notes/children\n",
    "            node = {col: (None if pd.isna(val) else val) for col, val in row.items()}\n",
    "            node['notes'] = []\n",
    "            node['children'] = []\n",
    "\n",
    "            # Attach node\n",
    "            if depth == 0:\n",
    "                root.append(node)\n",
    "            else:\n",
    "                ancestors = [d for d in level_nodes if d < depth]\n",
    "                if ancestors:\n",
    "                    parent = level_nodes[max(ancestors)]\n",
    "                    parent['children'].append(node)\n",
    "                else:\n",
    "                    root.append(node)\n",
    "\n",
    "            level_nodes[depth] = node\n",
    "\n",
    "        else:\n",
    "            # Note row: always attach to level-1 if present, else level-0\n",
    "            if 1 in level_nodes:\n",
    "                target = level_nodes[1]\n",
    "            elif 0 in level_nodes:\n",
    "                target = level_nodes[0]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            for col in note_text_cols:\n",
    "                text = row.get(col)\n",
    "                if pd.notna(text):\n",
    "                    target['notes'].append(str(text).strip())\n",
    "\n",
    "    return root\n",
    "\n",
    "# ─── USER SETTINGS ─────────────────────────────────────────────\n",
    "input_path      = 'Chapter25_clean.xlsx'    # your Excel file\n",
    "output_path     = 'hierarchy_ver3.json'    # desired JSON output\n",
    "level_col       = 'level'             # column for depth\n",
    "remark_col      = 'Remark'           # column marking 'Tariff'/'Notes'/'Chapter'\n",
    "note_text_cols  = [\n",
    "    'Item Description',\n",
    "    'Import Policy_text',\n",
    "    'Export Policy_text'\n",
    "]\n",
    "hs_code_col     = 'HS Code'          # column to normalize (remove spaces)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Load data, build hierarchy, and save JSON\n",
    "\n",
    "df = pd.read_excel(input_path)\n",
    "hierarchy = build_hierarchy(\n",
    "    df,\n",
    "    level_col=level_col,\n",
    "    remark_col=remark_col,\n",
    "    note_text_cols=note_text_cols,\n",
    "    hs_code_col=hs_code_col\n",
    ")\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as fp:\n",
    "    json.dump(hierarchy, fp, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved hierarchical JSON with {len(hierarchy)} top-level nodes to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
